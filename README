Wall-E Project
--------------

Introduction
============

Wall-E -project studies robots and controllers for them.
It is based on Adruino Pirate 4WD car, which carries Raprberry-PI to control it.
Remote controller is mobile phone like Android one or Maemo one or E7 ...
All parts are cheap and we use everything we already own.

All devices are programmed with their own native programming language.

Arduino Pirate 4WD car
----------------------

Role as Robot device, its "muscles"

This device is run by Romeo. Romeo is microcontroller and runs programs that are originally
written in C, compiled in host computer and uploaded by USB to the device. On this project we want
control Arduino by Raspberry PI computer, which native programming language is Python, so we load
pyfirmata sketch 1) to it.

Raspberry PI
------------

Role as Robot logic, it's "brains".

Raspberry PI computer is very small and very cheap. But is real computer running Linux.
We connect Raspberry PI and Arduino Romeo board by USB and set up Python server listening command
that come from WLAN from remote controller. We need a cheap WLAN USB-stick.
Python has fine libraries to read WLAN connections and handle serial line devices
that Romeo is seen in USB connection. Raspberry PI has two USB connection and we use them both, but we don't need
USB-HUB.

Raspberry PI carries also some integrated capabilities. We have two usb-microphones connected in 180 degrees angle,
so we have implemented position hearing, capability to know in what angle sound comes. We have learned Wall-E to turn to that direction.
It is very interested of it'sd environment, hoping to meet and see Eva, hoping to hold her hand one day (I haven't duid hands to Wall-E yet
but please don't tell that to Wall-E, maybe one day he has hands.)

Raspberry PI also has it's official camera, so we can see in remote controller what Wall-E sees.
Later we can use camera to recognize objects.




N900
----

Role as remote controller

N900 is Maemo mobile phone which runs Linux. It's native programming language is Qt C++, which is ideal to make
applications with graphical UI and WLAN-client. We study fancy logics how to control devices, so this as fine
platform to make them.


E7 or other Qt Phone
--------------------

Role as remote controller

E7 is mobile phone which runs Qt above Symbian. It runs same source code as N900 does.


Android Phone
-------------

Role as external Senses or remote controller

Android phone has many sensors we can use. Now position sense is ready.
Wall-E carries Android cheap and little phone, which t tells what is device's angle from north (azimuth).
This capability is needed to turn Wall-E toward the sounds it hears.

Android Phone's role can also same than N900, we can use it as remote controller. Android is programmed by Java and it has fine graphic libraries
and it can use WLAN connections. Unfortunately remote controller is not programmed for Android yet.

Theory of Robots
================

Robot implementation based on research domains including developmental psychology, cognitive neuroscience, and cognitive psycology, very popular areas
styudy with robotics.

Events Perception
-----------------

Robot can notice events using its sensories.

Goal driven action
------------------

Robot has goals, it makes decisions what actions are it makes to reach its goals. Implementation uses circle of event-decision-action to
make tasks to reach goals. Some Goals are more important than others, so we implement Maslow's Hierarchy of Needs to guide robots actions,
but robot itself has higher needs, its thinks is most important.

Starting point of Wall-E
========================

This comes from Wall-E film. Wall-E likes to watch people dancing and thinks it would be nice to hold
on hands with a girl robot. One day it see Eve, very graceful being, it can't set eyes off her. Here we gat most important goal of Wall-E,
hold Eve's hand. OK, we must build a robot that can find out Eve. So we must build at least hearing and seeing as a start.

Concept
=======

We must have sensorys. Project implements sensory framework sor simultaneous percertons
like we human can do, Axons to corry these percetions from interba√∂ sensorys and from exterbal sensorys to the brain.
Framewrk is veru flexible so Wall-E xan use all suitable devices we can offers (cheap devices we allreasy have or buy).

OK Lets Start, project has already object positioning using hearing and turning using position
sensory (azimuth) to that direction. Demo will be made to youtube.
Next target will be object recognize using seeing.



