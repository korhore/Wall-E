Critical
--------

Gets situation,where vonnection are dine repeatedly until we get max.
We must connect only best associations.

Created 3 SocketServer and 3 SockertClient threads/instances. 1 +1 is enough.

Communication
  OK Sensation.getBestSensation( sensationType = Sensation.SensationType.Item,
                                                                name = sensation.getName(),
                                                                timemin = None,
                                                                timemax = None,
                                                                associationSensationType=Sensation.SensationType.Voice)
  Newer gets sensation, so there is no way to communicate. Are voices connected to Items or not?
  Ceate an logger to detect, when Voice is connected to an Item




Association: use only one Item.name per association.
Find out best Voice, Image etc, per Item.name and connect tohose togetger.
When better one is found, remove worse association and connect better one.

Associations between sensations are neuro-network -like, so we must
study how to make
- Voide-tensorflow -model, where Item.name is connectod to a Voice handled
  like black-white (one-channel) image
- Item-tensorflow -model, where Item.Name is connected with other Item.name
  calculating how one thing will be happened same time as other thing

What is done
------------

- Architecture, that is
-- devided into Robots that are implemented by Bobots, meaning
--- inheritance
---- Robot can be anywhere in one running instance
--- multihosted, Robots can be anywhere in the world, in any host
-- identity
--- Robot knows some details of itself
-- Virtual instances
--- this is for testing purposes
---- We can create sensations to our Real instance and study how it reacts
     meaning that we can finally start to implement thast our Robots gets Sensations
     that nake to fall in love, our final goal, make a Robot that can feel.
     But before that we have some to do.
-- Static LongTerm Memory
---- All whar Robot knows about this worlds in imlemented as Senmation class
    instances which are connected with each other. Anything other way is used.
    This momocs human memory. 
--- When a rub stoppes, we can save satus of memory and kload it back, when
    new run starts 
-- Item
--- This is a Sensation connected to other Sensation, just a name of a thing
    and a  score for this
-- Tensorflow classification to analyse Images Robot gets. This produces
   Items connected to subImages, cropped from camera Images is Classification
   results. This proces gives to Robot capability so see thing and give a name
   to the seen things and capability to connect other Sensations like voices
   to this Item. This mimics our brain main functionality: we are good at 
   processing visual things and that is most that our brains do. That will be
   main thing Robot will do, just process Images and think what it has seen.
   
What is not done and needs implementation
-----------------------------------------

Robot.process
- divide into two phasess
-- processSensation(sensation)
--- if there is something in Axon, process it
    AlsaPlayback is ecaple of implementation and
    also LoggerRobot explayned below
-- produceSensation()
--- when Sensation are processed, we can sense: as a sense produce a sensation
    default implementation for this is empty, but AlsaMicrophone is an example of implementation,
    as well raspberryPiCamera
- Sensation
-- Sourcerobot

- LoggerRobot
-- interrested of everything
-- Logges current sensations by order
-- whows images seen by order, yhese are diffent we show
-- echoes voices heard, these are different than voices spoken

- LoadSpeakerRobot == AlsaAudioPlayBack, for communicating by Voices with Items
-- TODO howto implement Robot which code is same than other,
   but work and /etc directory is different?
--- We can implement links, same way than linux does
--- or just inherit a robot by import,
    this gives us possibility to separater technology (AlseSpearker) and role (mouth, logger)
- ViewerRobot, for communication by imeges with Items
- We can name of main class of a seen thing. Names are like 'person',
  'dining table', 'bicycle', 'tv' etc., but we cant yet identity things inside
  main class like 'John' is a 'person'. So Robot don't know id it sees 'John' or
  'Joan', it sees just 'person'.
-- implementing this needs
--- live Tesorflow model. We use now foren one. Learning means that we should
    find out characteristic things between 'John' and 'Joan'. These can be voice
    or some statistical thing in images like colors.
- Live Tensorflow model for voices. Image gives a name of seen thing. We connect
  name to voice heard same time thing has been seen. Most potential way to
  implement this kind Ternsorflow learning model for voices is use converting
  scalar voice information as one channel (blachwhite) image information as
  describet in Tensorflow voice analysing totorial pages.
- Expectations.
-- We can study statistically what is happening in hours of day,
  days in week, etc. and make Robot to wait that same kind thins happen and if
  Robot finds out that thing are going on in normal way, make Robot happy. We
  are implementing Feelings. We are near out goal are'nt we?
-- When something happens like we hear a voice identified to Sensorflow to
   a class name, meaning on Item with this name, connected to other kind Sensation
   like Image, we can implement expectation: if something happens, then it
   is expected to happen also something else. Here we can make our Robot happy
   if Robot is right and it has leaned something of thos world. We are even closer
   to our goal, are'nt we?
   
Dependencies
------------  

dependencies: for pillow (pip3 install pillow)
sudo apt-get install libjpeg-dev -y
sudo apt-get install zlib1g-dev -y
sudo apt-get install libfreetype6-dev -y
sudo apt-get install liblcms1-dev -y
sudo apt-get install libopenjp2-7 -y
sudo apt-get install libtiff5 -y

MainRobot needs
pip3 install daemon
pip3 install lockfile
pip3 install pyyaml # Required to save tensorflow models in YAML format

raspberry pi 3
tensorflow==1.8
Ubuntu 18.5
tensorflow==1.5
Ubuntu 14.04
sudo -H pip3 install --upgrade tensorflow --ignore-installed six
-- will get tensorflow 1.13
requires
google.protobuf
matplotlib==2.1.0
requires
- sudo apt-get install libfreetype6-dev